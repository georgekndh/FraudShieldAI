import os
import io
import json
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import matplotlib.pyplot as plt
import requests



st.sidebar.markdown("## üîå Live API")
use_live_api = st.sidebar.toggle("Score via API (no scored CSV needed)", value=True)
api_base = st.sidebar.text_input("API base URL", value="http://127.0.0.1:8000")
batch_size = st.sidebar.slider("Batch size", 100, 5000, 1000, step=100)
raw_file = st.sidebar.file_uploader("Raw CSV (unscored)", type=["csv"], key="raw_csv")


# Try to import shap lazily; show a friendly message if missing
try:
    import shap  # type: ignore
    SHAP_AVAILABLE = True
except Exception:
    SHAP_AVAILABLE = False

st.set_page_config(page_title="FraudShield AI ‚Äì Monitor", layout="wide")
st.title("üìü FraudShield AI ‚Äî Scored Transactions Monitor")

# Introductory user guidance
st.markdown(
"""
### üëã Welcome to FraudShield AI Dashboard
This dashboard helps you **analyze and visualize transaction fraud predictions** generated by your model.


**How to use:**
1. Upload a pre-scored CSV file containing a `fraud_probability` column, or use the default sample.
2. (Optional) Upload a `.pkl` model bundle to enable SHAP explanations.
3. Adjust the **decision threshold** using the sidebar slider to control fraud alert sensitivity.
4. View the *Top Suspicious Transactions*, overall summary metrics, and fraud score distributions below.


üí° **Note:** In all tables and charts, `1` indicates a **fraudulent transaction**, while `0` represents a **legitimate (non-fraud)** transaction.


üßÆ **E[f(X)]:** In SHAP plots, `E[f(X)]` represents the model's *expected baseline output* (average prediction before any feature effects). It shows the starting value from which SHAP contributions push the prediction toward fraud or legit.


üî¢ **Positive and negative values:** Positive SHAP values (shown in red) increase the model's prediction toward **fraudulent**, while negative SHAP values (blue) decrease the prediction toward **legitimate** transactions. The magnitude of each value indicates the strength of that feature's influence.
""",
unsafe_allow_html=True,
)

st.subheader("üèÜ Feature importance leaderboard (from API)")

if use_live_api:
    try:
        info = requests.get(f"{api_base.rstrip('/')}/model-info?top_k=30", timeout=15).json()
        imp = pd.DataFrame(info["feature_importance"])

        st.caption(f"Threshold: {info.get('threshold')}")
        st.dataframe(imp, use_container_width=True)

        # simple chart
        st.bar_chart(imp.set_index("feature")["importance"])
    except Exception as e:
        st.warning(f"Could not load feature importance from API: {e}")
else:
    st.info("Enable Live API mode to fetch feature importance.")


# ---------------------------
# Config & helpers
# ---------------------------
DEFAULT_SCORED_PATH = os.getenv("SCORED_CSV", "data/scored.csv")
DEFAULT_MODEL_PATH = os.getenv("MODEL_PATH", "models/fraudshield_lgbm.pkl")
THRESHOLD = float(os.getenv("THRESHOLD", 0.5))

@st.cache_data(show_spinner=False)
def load_scored_csv(default_path: str) -> pd.DataFrame:
    if os.path.exists(default_path):
        df = pd.read_csv(default_path)
        return df
    return pd.DataFrame()

@st.cache_resource(show_spinner=False)
def load_model(default_path: str):
    if os.path.exists(default_path):
        try:
            bundle = joblib.load(default_path)
            if isinstance(bundle, dict):
                pipe = bundle.get("pipeline", None)
                thr = bundle.get("threshold", None)
                return pipe, thr
            return bundle, None
        except Exception as e:
            st.warning(f"Couldn't load model: {e}")
    return None, None

def get_final_estimator(model_or_pipeline):
    if model_or_pipeline is None:
        return None
    if hasattr(model_or_pipeline, "steps") and hasattr(model_or_pipeline, "named_steps"):
        return model_or_pipeline.steps[-1][1]
    return model_or_pipeline

def is_tree_model(est) -> bool:
    name = type(est).__name__.lower() if est is not None else ""
    tree_like = [
        "lgbm", "lightgbm", "xgb", "xgboost", "catboost",
        "randomforest", "extratrees", "decisiontree", "gbclassifier", "gradientboosting"
    ]
    return any(t in name for t in tree_like)

def score_df_via_api(df_raw: pd.DataFrame, api_base: str, batch_size: int) -> pd.DataFrame:
    required_cols = ["Time", "Amount"] + [f"V{i}" for i in range(1, 29)]
    missing = [c for c in required_cols if c not in df_raw.columns]
    if missing:
        st.error(f"Missing required columns: {missing}")
        st.stop()

    rows = df_raw[required_cols].to_dict(orient="records")

    out_probs = []
    out_flags = []
    threshold = None

    url = f"{api_base.rstrip('/')}/score-batch"

    for i in range(0, len(rows), batch_size):
        chunk = rows[i:i+batch_size]
        payload = {"data": chunk}

        r = requests.post(url, json=payload, timeout=60)
        if r.status_code != 200:
            raise RuntimeError(f"API error {r.status_code}: {r.text}")

        preds = r.json()
        out_probs.extend([p["fraud_probability"] for p in preds])
        out_flags.extend([p["flag"] for p in preds])

        if threshold is None and len(preds) > 0:
            threshold = preds[0].get("threshold")

    df_scored = df_raw.copy()
    df_scored["fraud_probability"] = out_probs
    df_scored["flag"] = out_flags
    if threshold is not None:
        df_scored.attrs["threshold"] = threshold

    return df_scored


# ---------------------------
# Sidebar: data/model uploaders
# ---------------------------
with st.sidebar:
    st.header("‚öôÔ∏è Data & Model")
    st.caption("Load defaults from disk, or upload your own.")

    df_default = load_scored_csv(DEFAULT_SCORED_PATH)
    model_default, thr_from_bundle = load_model(DEFAULT_MODEL_PATH)

    if thr_from_bundle is not None:
        THRESHOLD = float(thr_from_bundle)

    up_scored = st.file_uploader("Scored CSV (must have 'fraud_probability')", type=["csv"])
    if up_scored is not None:
        df = pd.read_csv(up_scored)
    else:
        df = df_default.copy()

    up_model = st.file_uploader("Model/BUNDLE (.pkl)", type=["pkl"], help="Optional: needed for SHAP.")
    if up_model is not None:
        try:
            bundle = joblib.load(io.BytesIO(up_model.read()))
            if isinstance(bundle, dict):
                model = bundle.get("pipeline", None)
                thr2 = bundle.get("threshold", None)
                if thr2 is not None:
                    THRESHOLD = float(thr2)
            else:
                model = bundle
        except Exception as e:
            st.error(f"Failed to read uploaded model: {e}")
            model = None
    else:
        model = model_default

    st.divider()
    THRESHOLD = st.slider("Decision threshold", 0.0, 1.0, float(THRESHOLD), 0.01)

# Validate data
if df.empty:
    st.info("Upload a scored CSV from the sidebar, or place one at data/scored.csv.")
    st.stop()

if "fraud_probability" not in df.columns:
    st.error("CSV must include a 'fraud_probability' column.")
    st.stop()

NON_FEATURE_COLS = {"fraud_probability", "is_fraud", "label", "predicted_label", "txn_id"}
feature_cols = [c for c in df.columns if c not in NON_FEATURE_COLS]

# Dynamic classification

st.markdown(f"**Current Decision Threshold:** {THRESHOLD:.2f}")
df["predicted_label"] = (df["fraud_probability"] >= THRESHOLD).astype(int)
df_sorted_all = df.sort_values("fraud_probability", ascending=False).reset_index(drop=True)
df_flagged = df_sorted_all[df_sorted_all["predicted_label"] == 1]

# ---------------------------
# Top suspicious table + slider
# ---------------------------
left, right = st.columns([2, 1], gap="large")
with left:
    st.subheader("üö© Top suspicious")

    n = len(df_flagged) if len(df_flagged) > 0 else len(df_sorted_all)
    show_source = st.radio("Source:", ["Flagged only", "All (sorted by score)"], horizontal=True)
    src_df = df_flagged if show_source == "Flagged only" and len(df_flagged) > 0 else df_sorted_all

    n = len(src_df)
    max_n = min(2000, n)
    min_n = 1
    step_n = 1 if max_n < 10 else 10
    default_n = min(100, max_n)

    top_n = st.slider("Show top N", min_value=min_n, max_value=max_n, value=default_n, step=step_n)

    df_top = src_df.head(top_n)
    st.dataframe(df_top, use_container_width=True, height=420)

with right:
    st.subheader("Summary")
    alerts_flagged = int(df["predicted_label"].sum())
    avg_flagged = df.loc[df["predicted_label"] == 1, "fraud_probability"].mean()
    st.metric("Alerts flagged", alerts_flagged)
    st.metric("Avg score (flagged)", f"{avg_flagged:.6f}" if not np.isnan(avg_flagged) else "‚Äî")
    st.caption(f"Threshold = {THRESHOLD:.2f} | Total rows = {len(df):,} | Flag rate = {alerts_flagged/len(df):.3%}")
    st.download_button(
        label="Download scored CSV",
        data=df.to_csv(index=False).encode("utf-8"),
        file_name="scored_transactions.csv",
        mime="text/csv",
        use_container_width=True,
    )

# ---------------------------
# Probability distribution chart
# ---------------------------
st.subheader("üìä Score distribution")
use_log = st.toggle("Log scale", value=True, key="score_hist_log_toggle")
use_matplotlib = st.toggle("Use Matplotlib renderer (fallback)", value=False, help="Enable if Altair hides bars on rerun")

probs = df["fraud_probability"].astype(float).clip(0, 1 - 1e-9)
bins = np.linspace(0.0, 1.0, 81)
counts, edges = np.histogram(probs.values, bins=bins)
hist_df = pd.DataFrame({"x0": edges[:-1], "x1": edges[1:], "count": counts})

if not use_matplotlib:
    y_axis = alt.Y(
        'count:Q',
        scale=alt.Scale(type='log', clamp=True, domainMin=1) if use_log else alt.Scale(type='linear'),
        title='Count (log scale)' if use_log else 'Count'
    )

    zones = pd.DataFrame([
        {"x0": 0.0, "x1": THRESHOLD * 0.6, "label": "Safe"},
        {"x0": THRESHOLD * 0.6, "x1": THRESHOLD, "label": "Watch"},
        {"x0": THRESHOLD, "x1": 1.0, "label": "Flagged"},
    ])

    bands = alt.Chart(zones).mark_rect(opacity=0.12).encode(
        x='x0:Q', x2='x1:Q',
        color=alt.Color('label:N', scale=alt.Scale(domain=['Safe','Watch','Flagged'], range=['#16a34a','#f59e0b','#ef4444']), legend=alt.Legend(orient='top', title=None))
    ).properties(height=300)

    hist = alt.Chart(hist_df).mark_bar().encode(
        x=alt.X('x0:Q', bin=alt.Bin(binned=True), title='Predicted probability', scale=alt.Scale(domain=[0,1])),
        x2='x1:Q', y=y_axis
    ).properties(height=300)

    thr_line = alt.Chart(pd.DataFrame({'x':[THRESHOLD]})).mark_rule(color='red', strokeDash=[5,5]).encode(x='x:Q')

    st.altair_chart(bands + hist + thr_line, use_container_width=True)
else:
    fig, ax = plt.subplots(figsize=(8, 3.6))
    ax.hist(probs, bins=bins, log=use_log, edgecolor='#1E293B', color='#60A5FA')
    ax.axvspan(0.0, max(1e-6, THRESHOLD*0.6), color='#16a34a', alpha=0.12)
    ax.axvspan(THRESHOLD*0.6, THRESHOLD, color='#f59e0b', alpha=0.12)
    ax.axvspan(THRESHOLD, 1.0, color='#ef4444', alpha=0.12)
    ax.axvline(THRESHOLD, color='#ef4444', linestyle='--', linewidth=2)
    ax.set_xlim(0,1)
    ax.set_xlabel('Predicted probability')
    ax.set_ylabel('Count (log scale)' if use_log else 'Count')
    ax.grid(True, linestyle=':', alpha=0.3)
    st.pyplot(fig, clear_figure=True)

# ---------------------------
# SHAP explainer (local mode)
# ---------------------------
st.subheader("üß™ SHAP explainer (local)")

if SHAP_AVAILABLE and model is not None:
    # Pick source rows
    pick_source = st.radio("Pick from:", ["Top suspicious", "All rows"], horizontal=True)
    src_df = df_top if pick_source == "Top suspicious" else df_sorted_all

    # Select a row
    default_i = 0
    idx = st.selectbox(
        "Select a row",
        options=list(range(len(src_df))),
        index=default_i,
        format_func=lambda i: f"{src_df.index[i]} (score={src_df.iloc[i]['fraud_probability']:.4f})"
    )

    row = src_df.iloc[[idx]].copy()

    # ---- Build RAW feature frame (no targets, no scores) ----
    drop_cols = {"Class", "is_fraud", "fraud_probability", "flag", "txn_id"}
    raw_feature_cols = [c for c in feature_cols if c not in drop_cols and c in row.columns]

    X_raw = row[raw_feature_cols].copy()

    # ---- Get final estimator + (optionally) preprocessor ----
    final_est = get_final_estimator(model)

    # If model is a sklearn Pipeline, use its preprocessor step
    pre = None
    if hasattr(model, "named_steps"):
        # try common names first
        pre = model.named_steps.get("pre") or model.named_steps.get("preprocessor")
        # if not found, try "first step" heuristic
        if pre is None and len(model.named_steps) >= 2:
            first_key = list(model.named_steps.keys())[0]
            pre = model.named_steps[first_key]

    # Transform X the same way training did
    if pre is not None and hasattr(pre, "transform"):
        X_mat = pre.transform(X_raw)

        # Feature names after preprocessing (best-effort)
        try:
            feat_names = list(pre.get_feature_names_out())
        except Exception:
            # fallback: keep raw names (not perfect, but won't crash)
            feat_names = list(X_raw.columns)
    else:
        # No preprocessor found; explain raw features directly
        X_mat = X_raw.values
        feat_names = list(X_raw.columns)



        st.write("X_raw shape:", X_raw.shape)
        st.write("X_mat shape:", getattr(X_mat, "shape", None))
        st.write("n feature names:", len(feat_names)) 

    # ---- SHAP ----
    if not is_tree_model(final_est):
        st.info("SHAP local explainer only enabled for tree models in this demo.")
    else:
        with st.spinner("Computing SHAP values..."):
            explainer = shap.TreeExplainer(final_est)
            shap_values = explainer.shap_values(X_mat)

            # Handle binary classification outputs
            if isinstance(shap_values, list) and len(shap_values) == 2:
                sv = shap_values[1][0]
                expected = explainer.expected_value[1]
            else:
                # shap_values could be (n_samples, n_features) or (n_features,)
                if hasattr(shap_values, "ndim") and shap_values.ndim == 2:
                    sv = shap_values[0]
                else:
                    sv = shap_values
                expected = explainer.expected_value

            st.markdown("**SHAP waterfall (‚Üí fraud)**")
            fig, ax = plt.subplots(figsize=(6, 3.5))
            shap.plots._waterfall.waterfall_legacy(
                expected,
                sv,
                feature_names=feat_names,
                max_display=15,
                show=False,
            )
            plt.tight_layout()
            st.pyplot(fig, clear_figure=True)

            st.markdown("**Row feature values (raw)**")
            st.dataframe(X_raw.T.rename(columns={X_raw.index[0]: "value"}))


# ---------------------------
# Footer
# ---------------------------
st.caption("Built with ‚ù§Ô∏è for real-time fraud detection monitoring. ‚ìí FraudShield AI")
